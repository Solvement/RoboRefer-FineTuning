#!/usr/bin/env python3
"""
ä½¿ç”¨è®­ç»ƒåçš„ five_frames multi-image æ¨¡å‹åœ¨ CrossView benchmark ä¸Šæµ‹è¯•è·¨è§†è§’è¯†åˆ«

è¿™ä¸ªè„šæœ¬ä¼šï¼š
1. åŠ è½½è®­ç»ƒåçš„æ¨¡å‹
2. ä» five_frames æ•°æ®ä¸­æå– A å’Œ B å›¾ï¼ˆåŸºäº question.json ä¸­çš„ scene_id, frame_a_id, frame_b_idï¼‰
3. ä½¿ç”¨å¤šå›¾è¾“å…¥è¿›è¡Œæ¨ç†
4. ä¿å­˜ç»“æœå¹¶è®¡ç®—æŒ‡æ ‡
"""
import argparse
import json
import os
import sys
from pathlib import Path
from typing import List, Dict, Optional, Tuple
import torch
from PIL import Image
from tqdm import tqdm

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

try:
    from llava.model.builder import load_pretrained_model
    from llava.mm_utils import get_model_name_from_path, process_images, tokenizer_image_token
    from llava.constants import DEFAULT_IMAGE_TOKEN
    from transformers import AutoTokenizer
except ImportError as e:
    print(f"âŒ å¯¼å…¥å¤±è´¥: {e}")
    print("è¯·ç¡®ä¿åœ¨ RoboRefer ç›®å½•ä¸‹è¿è¡Œæ­¤è„šæœ¬")
    sys.exit(1)


def find_fiveframes_image(
    fiveframes_root: Path,
    scene_id: str,
    uid: str,
    frame_id: str,
    allow_fallback: bool = False
) -> Optional[Path]:
    """
    åœ¨ five_frames æ•°æ®ä¸­æŸ¥æ‰¾å¯¹åº”çš„ original å›¾åƒ
    
    Args:
        fiveframes_root: five_frames æ•°æ®æ ¹ç›®å½•
        scene_id: åœºæ™¯IDï¼ˆä¾‹å¦‚ "00777c41d4"ï¼‰
        uid: å®ä¾‹IDï¼ˆä¾‹å¦‚ "128"ï¼‰
        frame_id: å¸§IDï¼ˆä¾‹å¦‚ "001640"ï¼‰
        allow_fallback: å¦‚æœæ‰¾ä¸åˆ°æŒ‡å®šframe_idï¼Œæ˜¯å¦å…è®¸ä»five_frames.jsonä¸­éšæœºé€‰æ‹©ä¸€ä¸ª
    
    Returns:
        å›¾åƒè·¯å¾„ï¼Œå¦‚æœæ‰¾ä¸åˆ°è¿”å› None
    """
    # å°è¯• train å’Œ validation ä¸¤ä¸ªç›®å½•
    for split in ["train", "validation"]:
        # æ„é€ è·¯å¾„ï¼šsplit/scene_id/uid_xxx/XX_frame_id_original.png
        uid_dir = fiveframes_root / split / scene_id / f"uid_{uid}"
        if not uid_dir.exists():
            continue
        
        # æŸ¥æ‰¾åŒ¹é…çš„ original å›¾åƒ
        for img_file in uid_dir.glob(f"*_{frame_id}_original.png"):
            return img_file
        
        # å¦‚æœæ²¡æ‰¾åˆ°ï¼Œå°è¯•æŸ¥æ‰¾ five_frames.json æ¥ç¡®å®šæ–‡ä»¶åæ ¼å¼
        json_file = uid_dir / f"{scene_id}_uid_{uid}_five_frames.json"
        if json_file.exists():
            try:
                with open(json_file, 'r') as f:
                    frames_data = json.load(f)
                for frame_data in frames_data:
                    if str(frame_data.get("frame_id", "")) == str(frame_id):
                        original_path = Path(frame_data.get("original", ""))
                        if original_path.exists():
                            return original_path
                        # å°è¯•ç›¸å¯¹è·¯å¾„
                        rel_path = uid_dir / original_path.name
                        if rel_path.exists():
                            return rel_path
                
                # å¦‚æœallow_fallback=Trueä¸”æ²¡æ‰¾åˆ°æŒ‡å®šframe_idï¼Œéšæœºé€‰æ‹©ä¸€ä¸ªå¯ç”¨çš„frame
                if allow_fallback and len(frames_data) > 0:
                    import random
                    fallback_frame = random.choice(frames_data)
                    original_path = Path(fallback_frame.get("original", ""))
                    if original_path.exists():
                        return original_path
                    # å°è¯•ç›¸å¯¹è·¯å¾„
                    rel_path = uid_dir / original_path.name
                    if rel_path.exists():
                        return rel_path
            except Exception as e:
                print(f"âš ï¸  è¯»å– {json_file} å¤±è´¥: {e}")
                continue
    
    return None


def load_model(model_path: str, device: str = "cuda"):
    """åŠ è½½è®­ç»ƒåçš„æ¨¡å‹"""
    print(f"ğŸ“¦ åŠ è½½æ¨¡å‹: {model_path}")
    
    model_name = get_model_name_from_path(model_path)
    if not model_name or model_name == "":
        # å¦‚æœè·å–å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼
        model_name = "roborefer"
        print(f"âš ï¸  æ— æ³•ä»è·¯å¾„è·å–model_nameï¼Œä½¿ç”¨é»˜è®¤å€¼: {model_name}")
    
    print(f"ğŸ“ Model name: {model_name}")
    tokenizer, model, image_processor, context_len = load_pretrained_model(
        model_path, model_name, None, device_map=device, load_8bit=False, load_4bit=False
    )
    
    print(f"âœ… æ¨¡å‹åŠ è½½å®Œæˆ")
    return tokenizer, model, image_processor


def inference_multi_image(
    model,
    tokenizer,
    image_processor,
    image_a_path: Path,
    image_b_path: Path,
    prompt: str,
    device: str = "cuda"
) -> str:
    """
    ä½¿ç”¨å¤šå›¾è¾“å…¥è¿›è¡Œæ¨ç†
    
    Args:
        model: åŠ è½½çš„æ¨¡å‹
        tokenizer: tokenizer
        image_processor: å›¾åƒå¤„ç†å™¨
        image_a_path: A å›¾è·¯å¾„
        image_b_path: B å›¾è·¯å¾„
        prompt: æç¤ºè¯
        device: è®¾å¤‡
    
    Returns:
        æ¨¡å‹è¾“å‡ºæ–‡æœ¬
    """
    # åŠ è½½å›¾åƒ
    image_a = Image.open(image_a_path).convert("RGB")
    image_b = Image.open(image_b_path).convert("RGB")
    
    # å¤„ç†å›¾åƒ - ç›´æ¥ä½¿ç”¨ image_processor
    # ä¸ºæ¯å¼ å›¾æ·»åŠ  batch ç»´åº¦ï¼Œç„¶å stack
    processed_a = image_processor.preprocess(image_a, return_tensors="pt")["pixel_values"][0]  # [C, H, W]
    processed_b = image_processor.preprocess(image_b, return_tensors="pt")["pixel_values"][0]  # [C, H, W]
    # ä½¿ç”¨ half() è½¬æ¢ä¸º float16ï¼ˆä¸è®­ç»ƒæ—¶ä¸€è‡´ï¼‰
    processed_a = processed_a.half()
    processed_b = processed_b.half()
    image_tensors = torch.stack([processed_a, processed_b], dim=0)  # [2, C, H, W]
    
    # å¤„ç† promptï¼ˆæ·»åŠ å›¾åƒtokenï¼Œä¸¤å¼ å›¾éœ€è¦ä¸¤ä¸ªtokenï¼‰
    if DEFAULT_IMAGE_TOKEN not in prompt:
        prompt = f"{DEFAULT_IMAGE_TOKEN}\n{DEFAULT_IMAGE_TOKEN}\n" + prompt
    else:
        # å¦‚æœå·²ç»æœ‰tokenï¼Œç¡®ä¿æœ‰ä¸¤ä¸ªï¼ˆå¯¹åº”ä¸¤å¼ å›¾ï¼‰
        token_count = prompt.count(DEFAULT_IMAGE_TOKEN)
        if token_count < 2:
            prompt = f"{DEFAULT_IMAGE_TOKEN}\n" * (2 - token_count) + prompt
    
    # Tokenize
    input_ids = tokenizer_image_token(prompt, tokenizer, return_tensors="pt").unsqueeze(0).to(device)
    
    # æ¨ç† - ä½¿ç”¨ media å‚æ•°ï¼ˆæ ¼å¼ï¼šDict[str, List[torch.Tensor]]ï¼‰
    # å°† [2, C, H, W] çš„ tensor æ‹†åˆ†æˆä¸¤ä¸ª [C, H, W] çš„ tensor
    # ç¡®ä¿åœ¨æ­£ç¡®çš„è®¾å¤‡ä¸Šï¼Œå¹¶ä½¿ç”¨halfç²¾åº¦ï¼ˆä¸è®­ç»ƒæ—¶ä¸€è‡´ï¼‰
    image_tensors_list = [
        image_tensors[i].to(device=device, dtype=torch.float16) 
        for i in range(image_tensors.shape[0])
    ]
    media = {"image": image_tensors_list}
    media_config = {"image": {}}
    
    # ç¡®ä¿æ¨¡å‹åœ¨evalæ¨¡å¼
    model.eval()
    
    with torch.inference_mode():
        output_ids = model.generate(
            input_ids,
            media=media,
            media_config=media_config,
            do_sample=False,
            temperature=None,
            top_p=None,
            num_beams=1,
            max_new_tokens=100,  # å¢åŠ åˆ°100ï¼Œç¡®ä¿èƒ½ç”Ÿæˆå®Œæ•´çš„åæ ‡æ ¼å¼
            use_cache=True,
            pad_token_id=tokenizer.eos_token_id,  # è®¾ç½®pad token
        )
    
    # è§£ç è¾“å‡º
    raw_output = tokenizer.batch_decode(output_ids, skip_special_tokens=True)[0].strip()
    
    # ç§»é™¤è¾“å…¥éƒ¨åˆ†
    if prompt in raw_output:
        output = raw_output.replace(prompt, "").strip()
    else:
        output = raw_output
    
    # ä¿å­˜åŸå§‹è¾“å‡ºç”¨äºè°ƒè¯•
    import os
    if os.environ.get("DEBUG_OUTPUT", "0") == "1":
        print(f"DEBUG: åŸå§‹è¾“å‡º: {repr(output)}")
        print(f"DEBUG: è¾“å‡ºé•¿åº¦: {len(output)}")
    
    # åå¤„ç†ï¼šæå–æœ‰æ•ˆçš„åæ ‡æ ¼å¼æˆ–NOT_VISIBLE
    processed_output = extract_valid_output(output)
    
    # å¦‚æœå¤„ç†åè¾“å‡ºä¸å®Œæ•´ï¼Œè¿”å›åŸå§‹è¾“å‡ºçš„ä¸€éƒ¨åˆ†ç”¨äºè°ƒè¯•
    if processed_output == output[:100] and len(output) > 20:
        # è¯´æ˜extract_valid_outputæ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆæ ¼å¼ï¼Œè¿”å›åŸå§‹è¾“å‡ºç”¨äºåˆ†æ
        return output[:200]  # è¿”å›å‰200å­—ç¬¦ç”¨äºåˆ†æ
    
    return processed_output


def extract_valid_output(text: str) -> str:
    """
    ä»æ¨¡å‹è¾“å‡ºä¸­æå–æœ‰æ•ˆçš„åæ ‡æ ¼å¼æˆ–NOT_VISIBLE
    
    Args:
        text: æ¨¡å‹åŸå§‹è¾“å‡º
    
    Returns:
        æå–åçš„æœ‰æ•ˆè¾“å‡ºï¼š[(x, y)] æˆ– NOT_VISIBLE
    """
    import re
    
    # å…ˆæ£€æŸ¥æ˜¯å¦æœ‰NOT_VISIBLE
    if "NOT_VISIBLE" in text.upper():
        return "NOT_VISIBLE"
    
    # å°è¯•æå–ç¬¬ä¸€ä¸ªå®Œæ•´çš„åæ ‡æ ¼å¼ [(x, y)]
    # åŒ¹é…æ ¼å¼ï¼š[(æ•°å­—, æ•°å­—)] æˆ– [(æ•°å­—,æ•°å­—)]
    pattern = r'\[\(([0-9.]+),\s*([0-9.]+)\)\]'
    match = re.search(pattern, text)
    if match:
        x, y = match.groups()
        # éªŒè¯åæ ‡èŒƒå›´ [0, 1]
        try:
            x_val = float(x)
            y_val = float(y)
            if 0.0 <= x_val <= 1.0 and 0.0 <= y_val <= 1.0:
                return f"[({x}, {y})]"
        except ValueError:
            pass
    
    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°å®Œæ•´æ ¼å¼ï¼Œå°è¯•ä»å¼€å§‹éƒ¨åˆ†æå–
    # æ¨¡å‹è¾“å‡ºé€šå¸¸æ˜¯ [(0.100[([([... è¿™ç§æ ¼å¼
    # æˆ‘ä»¬éœ€è¦æå– [(0.100 åé¢çš„æ•°å­—
    # å…ˆæ‰¾åˆ° [(æ•°å­— çš„æ¨¡å¼
    pattern_start = r'\[\(([0-9.]+)'
    match_start = re.search(pattern_start, text)
    if match_start:
        first_num = match_start.group(1)
        # ç„¶åå°è¯•æ‰¾åˆ°ç¬¬äºŒä¸ªæ•°å­—ï¼ˆå¯èƒ½åœ¨åé¢ï¼‰
        # ç”±äºæ ¼å¼æ˜¯ [(0.100[(0. æˆ– [(0.100[([([ï¼Œæˆ‘ä»¬éœ€è¦æ›´çµæ´»çš„åŒ¹é…
        # å°è¯•åŒ¹é… [(æ•°å­—, æ•°å­— æˆ– [(æ•°å­—[(æ•°å­—
        pattern_two = r'\[\(([0-9.]+)[,\[\(]([0-9.]+)'
        match_two = re.search(pattern_two, text)
        if match_two:
            x, y = match_two.groups()
            try:
                x_val = float(x)
                y_val = float(y)
                if 0.0 <= x_val <= 1.0 and 0.0 <= y_val <= 1.0:
                    return f"[({x}, {y})]"
            except ValueError:
                pass
        
        # å¦‚æœåªæ‰¾åˆ°ä¸€ä¸ªæ•°å­—ï¼Œå°è¯•ä»é‡å¤çš„æ‹¬å·ä¸­æå–ç¬¬äºŒä¸ª
        # ä¾‹å¦‚ï¼š[(0.100[(0. è¿™ç§æƒ…å†µ
        pattern_second = r'\[\(([0-9.]+)\)?\[\(([0-9.]+)'
        match_second = re.search(pattern_second, text)
        if match_second:
            x, y = match_second.groups()
            try:
                x_val = float(x)
                y_val = float(y)
                if 0.0 <= x_val <= 1.0 and 0.0 <= y_val <= 1.0:
                    return f"[({x}, {y})]"
            except ValueError:
                pass
    
    # å¦‚æœéƒ½æ²¡æœ‰æ‰¾åˆ°ï¼Œå°è¯•æ›´å®½æ¾çš„åŒ¹é…ï¼šæ‰¾åˆ°ä¸¤ä¸ªæ•°å­—
    # åŒ¹é…æ ¼å¼ï¼šæ•°å­—.æ•°å­—ï¼ˆä¾‹å¦‚ 0.100ï¼‰
    numbers = re.findall(r'([0-9]\.[0-9]+)', text)
    if len(numbers) >= 2:
        try:
            x_val = float(numbers[0])
            y_val = float(numbers[1])
            if 0.0 <= x_val <= 1.0 and 0.0 <= y_val <= 1.0:
                return f"[({numbers[0]}, {numbers[1]})]"
        except (ValueError, IndexError):
            pass
    
    # å¦‚æœåªæ‰¾åˆ°ä¸€ä¸ªæ•°å­—ï¼Œå°è¯•ä»è¾“å‡ºå¼€å§‹éƒ¨åˆ†æå–
    # æ¨¡å‹è¾“å‡ºé€šå¸¸æ˜¯ [(0.100[([... æˆ– [(0.100, 0.)
    # å°è¯•åŒ¹é… [(æ•°å­—, æ•°å­—) æˆ– [(æ•°å­—,æ•°å­—
    pattern_incomplete = r'\[\(([0-9.]+),\s*([0-9.]+)\)'
    match_incomplete = re.search(pattern_incomplete, text)
    if match_incomplete:
        x, y = match_incomplete.groups()
        try:
            x_val = float(x)
            # yå¯èƒ½æ˜¯ "0." è¿™ç§ä¸å®Œæ•´æ ¼å¼ï¼Œéœ€è¦å¤„ç†
            if y.endswith('.'):
                # å¦‚æœyä»¥.ç»“å°¾ï¼Œå¯èƒ½æ˜¯0.0ï¼Œå°è¯•è¡¥å…¨
                y = y.rstrip('.') + '0'
            y_val = float(y)
            if 0.0 <= x_val <= 1.0 and 0.0 <= y_val <= 1.0:
                return f"[({x}, {y})]"
        except ValueError:
            pass
    
    # å¦‚æœéƒ½æ²¡æœ‰æ‰¾åˆ°ï¼Œè¿”å›åŸå§‹è¾“å‡ºï¼ˆç”¨äºè°ƒè¯•ï¼‰
    return text[:100]  # åªè¿”å›å‰100å­—ç¬¦ï¼Œé¿å…å¤ªé•¿


def test_crossview_benchmark(
    model_path: str,
    question_json: Path,
    fiveframes_root: Path,
    output_json: Path,
    device: str = "cuda",
    max_samples: Optional[int] = None
):
    """
    åœ¨ CrossView benchmark ä¸Šæµ‹è¯•æ¨¡å‹
    
    Args:
        model_path: è®­ç»ƒåçš„æ¨¡å‹è·¯å¾„
        question_json: CrossView question.json è·¯å¾„
        fiveframes_root: five_frames æ•°æ®æ ¹ç›®å½•
        output_json: è¾“å‡ºç»“æœ JSON è·¯å¾„
        device: è®¾å¤‡
        max_samples: æœ€å¤§æµ‹è¯•æ ·æœ¬æ•°ï¼ˆNone è¡¨ç¤ºå…¨éƒ¨ï¼‰
    """
    print(f"ğŸ“– åŠ è½½é—®é¢˜é›†: {question_json}")
    with open(question_json, 'r') as f:
        questions = json.load(f)
    
    if max_samples:
        questions = questions[:max_samples]
        print(f"âš ï¸  é™åˆ¶æµ‹è¯•æ ·æœ¬æ•°: {max_samples}")
    
    print(f"âœ… å…± {len(questions)} ä¸ªæµ‹è¯•æ ·æœ¬")
    
    # åŠ è½½æ¨¡å‹
    tokenizer, model, image_processor = load_model(model_path, device)
    
    # å‡†å¤‡è¾“å‡º
    results = []
    failed = 0
    
    # æ„é€ å¤šå›¾ cross-view promptï¼ˆä¸è®­ç»ƒæ—¶ä¸€è‡´ï¼‰
    def build_multiimage_prompt(label: str) -> str:
        return (
            "You are given TWO separate images:\n"
            "- Image A (REFERENCE): the target object is highlighted (marked) in the image.\n"
            "- Image B (QUERY): you need to find the SAME object as in Image A.\n\n"
            f"The target in Image A is a \"{label}\". It is visually marked, so you can clearly see which object to track.\n\n"
            "TASK:\n"
            "1. Look at Image A and understand which object is marked.\n"
            "2. Look at Image B and determine whether the SAME object is visible.\n"
            "3. If the object is visible in Image B, output ONE point coordinate on that object.\n"
            "4. If the object is NOT visible in Image B, answer NOT_VISIBLE.\n\n"
            "OUTPUT FORMAT:\n"
            "- If visible: answer with one coordinate in normalized [0,1] range relative to Image B only, in the form: [(x, y)]\n"
            "- If NOT visible: answer exactly: NOT_VISIBLE\n"
        )
    
    # æµ‹è¯•æ¯ä¸ªæ ·æœ¬
    for i, q in enumerate(tqdm(questions, desc="æµ‹è¯•ä¸­")):
        scene_id = q.get("scene_id", "")
        uid = q.get("uid", "")
        frame_a_id = q.get("frame_a_id", "")
        frame_b_id = q.get("frame_b_id", "")
        label = q.get("object", "")
        
        # æŸ¥æ‰¾ A å’Œ B å›¾
        # Aå›¾å…è®¸fallbackï¼ˆå¦‚æœæ‰¾ä¸åˆ°æŒ‡å®šframe_idï¼Œä»five_framesä¸­éšæœºé€‰ä¸€ä¸ªï¼‰
        # Bå›¾ä¸å…è®¸fallbackï¼ˆå¿…é¡»æ˜¯æŒ‡å®šçš„frame_idï¼‰
        image_a_path = find_fiveframes_image(fiveframes_root, scene_id, uid, frame_a_id, allow_fallback=True)
        image_b_path = find_fiveframes_image(fiveframes_root, scene_id, uid, frame_b_id, allow_fallback=False)
        
        if image_a_path is None or image_b_path is None:
            print(f"âš ï¸  æ ·æœ¬ {q['id']}: æ‰¾ä¸åˆ°å›¾åƒ")
            print(f"   A: {image_a_path}, B: {image_b_path}")
            failed += 1
            results.append({
                "question_id": q["id"],
                "text": "ERROR: Image not found",
                "model_id": "fiveframes_multiimage",
                "rgb_path": q.get("rgb_path", ""),
                "mask_path": q.get("mask_path", ""),
            })
            continue
        
        # æ„é€  prompt
        prompt = build_multiimage_prompt(label)
        
        # æ¨ç†
        try:
            output = inference_multi_image(
                model, tokenizer, image_processor,
                image_a_path, image_b_path, prompt, device
            )
        except Exception as e:
            import traceback
            print(f"âŒ æ ·æœ¬ {q['id']} æ¨ç†å¤±è´¥: {e}")
            print(f"   è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
            failed += 1
            output = f"ERROR: {str(e)}"
        
        # æå–GTåæ ‡ï¼ˆä»five_framesæ•°æ®ä¸­ï¼‰
        gt_coord = None
        try:
            five_frames_file = fiveframes_root / scene_id / f"uid_{uid}" / f"{scene_id}_uid_{uid}_five_frames.json"
            if five_frames_file.exists():
                with open(five_frames_file, 'r') as f:
                    five_frames_data = json.load(f)
                    # æ‰¾åˆ°frame_b_idå¯¹åº”çš„æ•°æ®
                    for frame_data in five_frames_data:
                        if frame_data.get("frame_id") == frame_b_id:
                            gt_coord = (frame_data.get("cx_norm"), frame_data.get("cy_norm"))
                            break
        except Exception as e:
            pass  # å¦‚æœæ‰¾ä¸åˆ°GTåæ ‡ï¼Œç»§ç»­å¤„ç†
        
        # ä¿å­˜ç»“æœï¼ˆåŒ…å«GTåæ ‡ç”¨äºåç»­è¯„ä¼°ï¼‰
        result = {
            "question_id": q["id"],
            "prompt": prompt,
            "object_name": label,
            "text": output,
            "model_id": "fiveframes_multiimage",
            "rgb_path": q.get("rgb_path", ""),
            "mask_path": q.get("mask_path", ""),
            "category": q.get("category", ""),
            "step": q.get("step", 1),
        }
        
        # å¦‚æœæœ‰GTåæ ‡ï¼Œæ·»åŠ åˆ°ç»“æœä¸­
        if gt_coord:
            result["gt_coord"] = gt_coord
        
        results.append(result)
    
    # ä¿å­˜ç»“æœ
    output_json.parent.mkdir(parents=True, exist_ok=True)
    with open(output_json, 'w') as f:
        for r in results:
            f.write(json.dumps(r, ensure_ascii=False) + "\n")
    
    print(f"\nâœ… æµ‹è¯•å®Œæˆ!")
    print(f"   - æ€»æ ·æœ¬æ•°: {len(questions)}")
    print(f"   - æˆåŠŸ: {len(questions) - failed}")
    print(f"   - å¤±è´¥: {failed}")
    print(f"   - ç»“æœä¿å­˜åˆ°: {output_json}")


def main():
    parser = argparse.ArgumentParser(
        description="ä½¿ç”¨è®­ç»ƒåçš„ five_frames multi-image æ¨¡å‹æµ‹è¯• CrossView benchmark"
    )
    parser.add_argument(
        "--model_path",
        type=str,
        required=True,
        help="è®­ç»ƒåçš„æ¨¡å‹è·¯å¾„ï¼Œä¾‹å¦‚: runs/train/RoboRefer-2B-FiveFrames-MultiImage/model"
    )
    parser.add_argument(
        "--question_json",
        type=str,
        required=True,
        help="CrossView question.json è·¯å¾„"
    )
    parser.add_argument(
        "--fiveframes_root",
        type=str,
        required=True,
        help="five_frames æ•°æ®æ ¹ç›®å½•"
    )
    parser.add_argument(
        "--output_json",
        type=str,
        required=True,
        help="è¾“å‡ºç»“æœ JSON è·¯å¾„ï¼ˆJSONL æ ¼å¼ï¼‰"
    )
    parser.add_argument(
        "--device",
        type=str,
        default="cuda",
        help="è®¾å¤‡ (cuda/cpu)"
    )
    parser.add_argument(
        "--max_samples",
        type=int,
        default=None,
        help="æœ€å¤§æµ‹è¯•æ ·æœ¬æ•°ï¼ˆç”¨äºå¿«é€Ÿæµ‹è¯•ï¼‰"
    )
    
    args = parser.parse_args()
    
    test_crossview_benchmark(
        model_path=args.model_path,
        question_json=Path(args.question_json),
        fiveframes_root=Path(args.fiveframes_root),
        output_json=Path(args.output_json),
        device=args.device,
        max_samples=args.max_samples
    )


if __name__ == "__main__":
    main()
