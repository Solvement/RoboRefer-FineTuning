#!/usr/bin/env python3
"""
æ„å»ºå¤šè§†è§’ä¸€è‡´æ€§SFTè®­ç»ƒæ•°æ®

ä» five_frames æ•°æ®ç”Ÿæˆå¤šå›¾æ ¼å¼çš„è®­ç»ƒæ•°æ®ï¼š
- Image A: æ ‡è®°äº†ç›®æ ‡ç‰©ä½“çš„å‚è€ƒå›¾åƒï¼ˆçº¢è‰²overlayï¼‰
- Image B: æŸ¥è¯¢å›¾åƒï¼ˆåŸå§‹å›¾åƒï¼‰
- GT: Image Bä¸­çš„å½’ä¸€åŒ–åæ ‡æˆ–NOT_VISIBLE
"""

import argparse
import json
import random
import re
from pathlib import Path
from typing import List, Dict, Any, Tuple, Optional

import cv2
import numpy as np
from PIL import Image, ImageDraw


def load_mask(mask_path: Path) -> Optional[np.ndarray]:
    """è¯»å–maskä¸ºç°åº¦å›¾ï¼›è¯»å–å¤±è´¥è¿”å›Noneã€‚"""
    if not mask_path.exists():
        return None
    m = cv2.imread(str(mask_path), cv2.IMREAD_GRAYSCALE)
    return m


def compute_mask_centroid(mask: np.ndarray) -> Optional[Tuple[float, float]]:
    """
    è®¡ç®—maskçš„è´¨å¿ƒï¼ˆå½’ä¸€åŒ–åæ ‡ï¼‰
    è¿”å›: (x_norm, y_norm) æˆ– Noneï¼ˆå¦‚æœmaskä¸ºç©ºï¼‰
    """
    ys, xs = np.where(mask > 0)
    if len(xs) == 0:
        return None
    h, w = mask.shape
    x_center = np.mean(xs)
    y_center = np.mean(ys)
    return (x_center / (w - 1), y_center / (h - 1))


def create_marked_image(original_path: Path, mask: np.ndarray, alpha: float = 0.45) -> Image.Image:
    """
    åˆ›å»ºæ ‡è®°å›¾åƒï¼šåœ¨åŸå§‹å›¾åƒä¸Šå åŠ çº¢è‰²mask
    """
    img = Image.open(original_path).convert("RGB")
    img_array = np.array(img)
    
    # åˆ›å»ºçº¢è‰²overlay
    overlay = img_array.copy()
    overlay[mask > 0] = [255, 0, 0]  # çº¢è‰²
    
    # æ··åˆ
    mask_3d = (mask > 0)[:, :, np.newaxis].astype(float)
    marked = (img_array * (1 - alpha * mask_3d) + overlay * (alpha * mask_3d)).astype(np.uint8)
    
    return Image.fromarray(marked)


def build_human_prompt() -> str:
    """æ„å»ºhuman promptï¼ˆä¸åŒ…å«<image> tokenï¼Œdatasetä¼šè‡ªåŠ¨æ’å…¥ï¼‰"""
    return "You are given TWO separate images:\n- Image A (REFERENCE): the target object is highlighted (marked) in the image.\n- Image B (QUERY): you need to find the SAME object as in Image A.\n\nTASK:\n1. Look at Image A and understand which object is marked.\n2. Look at Image B and determine whether the SAME object is visible.\n3. If the object is visible in Image B, output ONE point coordinate on that object.\n4. If the object is NOT visible in Image B, answer NOT_VISIBLE.\n\nOUTPUT FORMAT:\n- If visible: answer with one coordinate in normalized [0,1] range relative to Image B only, in the form: [(x, y)]\n- If NOT visible: answer exactly: NOT_VISIBLE"


def find_frame_files(uid_dir: Path, k: int) -> Tuple[Optional[Path], Optional[Path]]:
    """
    æŸ¥æ‰¾ç¬¬kä¸ªviewçš„æ–‡ä»¶ï¼ˆk=1..5ï¼‰
    è¿”å›: (original_path, mask_path) æˆ– (None, None)
    """
    k_str = f"{k:02d}"
    pattern_orig = f"{k_str}_*_original.png"
    pattern_mask_dilated = f"{k_str}_*_mask_dialated.png"
    pattern_mask = f"{k_str}_*_mask.png"
    
    orig_files = list(uid_dir.glob(pattern_orig))
    if not orig_files:
        return None, None
    
    orig_path = orig_files[0]
    
    # ä¼˜å…ˆä½¿ç”¨mask_dialatedï¼Œå¦åˆ™ä½¿ç”¨mask
    mask_dilated = list(uid_dir.glob(pattern_mask_dilated))
    mask_files = list(uid_dir.glob(pattern_mask))
    
    if mask_dilated:
        mask_path = mask_dilated[0]
    elif mask_files:
        mask_path = mask_files[0]
    else:
        mask_path = None
    
    return orig_path, mask_path


def extract_frame_id(filename: str) -> str:
    """ä»æ–‡ä»¶åæå–frame_idï¼ˆä¾‹å¦‚ï¼š01_004130_original.png -> 004130ï¼‰"""
    match = re.search(r'_\d+_', filename)
    if match:
        return match.group(0)[1:-1]  # å»æ‰å‰åçš„ä¸‹åˆ’çº¿
    return "unknown"


def build_samples_for_uid(
    scene_id: str,
    uid: str,
    uid_dir: Path,
    marked_dir: Path,
    split: str,
    mode: str,
    anchor_k: int,
    alpha: float,
    seed: int,
) -> List[Dict[str, Any]]:
    """
    ä¸ºå•ä¸ªuidæ„å»ºæ‰€æœ‰æ ·æœ¬
    """
    random.seed(seed)
    
    # æ”¶é›†5ä¸ªviewçš„æ•°æ®
    views = {}
    for k in range(1, 6):
        orig_path, mask_path = find_frame_files(uid_dir, k)
        if orig_path is None:
            continue
        
        mask = None
        if mask_path:
            mask = load_mask(mask_path)
        
        if mask is None:
            continue
        
        # è®¡ç®—GTç‚¹
        gt_point = compute_mask_centroid(mask)
        
        # æå–frame_id
        frame_id = extract_frame_id(orig_path.name)
        
        # åˆ›å»ºæ ‡è®°å›¾åƒ
        marked_rel = Path(split) / scene_id / f"uid_{uid}" / f"{k:02d}_{frame_id}_marked.png"
        marked_full = marked_dir / marked_rel
        marked_full.parent.mkdir(parents=True, exist_ok=True)
        
        marked_img = create_marked_image(orig_path, mask, alpha)
        marked_img.save(marked_full)
        
        views[k] = {
            "k": k,
            "frame_id": frame_id,
            "original_path": orig_path.resolve(),  # ç»å¯¹è·¯å¾„
            "mask": mask,
            "gt_point": gt_point,
            "marked_path": marked_full.resolve(),  # ç»å¯¹è·¯å¾„
        }
    
    if len(views) < 2:
        return []  # è‡³å°‘éœ€è¦2ä¸ªviewæ‰èƒ½é…å¯¹
    
    samples = []
    
    # ç”Ÿæˆé…å¯¹
    if mode == "anchor":
        # anchoræ¨¡å¼ï¼šä½¿ç”¨anchor_kä½œä¸ºAï¼Œå…¶ä»–viewä½œä¸ºB
        if anchor_k not in views:
            return []
        
        ref_view = views[anchor_k]
        for k, query_view in views.items():
            if k == anchor_k:
                continue
            
            # åˆ›å»ºæ ·æœ¬
            sample_id = f"{scene_id}_uid{uid}_A{ref_view['k']:02d}{ref_view['frame_id']}_B{query_view['k']:02d}{query_view['frame_id']}"
            
            gt_value = "NOT_VISIBLE" if query_view['gt_point'] is None else f"[({query_view['gt_point'][0]:.3f}, {query_view['gt_point'][1]:.3f})]"
            
            sample = {
                "id": sample_id,
                "image": [
                    str(ref_view['marked_path']),  # Image A: æ ‡è®°å›¾åƒï¼ˆç»å¯¹è·¯å¾„ï¼‰
                    str(query_view['original_path'])  # Image B: åŸå§‹å›¾åƒï¼ˆç»å¯¹è·¯å¾„ï¼‰
                ],
                "conversations": [
                    {"from": "human", "value": build_human_prompt()},
                    {"from": "gpt", "value": gt_value}
                ]
            }
            samples.append(sample)
    
    elif mode == "allpairs":
        # allpairsæ¨¡å¼ï¼šæ‰€æœ‰æœ‰å‘å¯¹
        for k_a, view_a in views.items():
            for k_b, view_b in views.items():
                if k_a == k_b:
                    continue
                
                sample_id = f"{scene_id}_uid{uid}_A{view_a['k']:02d}{view_a['frame_id']}_B{view_b['k']:02d}{view_b['frame_id']}"
                
                gt_value = "NOT_VISIBLE" if view_b['gt_point'] is None else f"[({view_b['gt_point'][0]:.3f}, {view_b['gt_point'][1]:.3f})]"
                
                sample = {
                    "id": sample_id,
                    "image": [
                        str(view_a['marked_path']),
                        str(view_b['original_path'])
                    ],
                    "conversations": [
                        {"from": "human", "value": build_human_prompt()},
                        {"from": "gpt", "value": gt_value}
                    ]
                }
                samples.append(sample)
    
    return samples


def add_hard_negatives(
    samples: List[Dict[str, Any]],
    scene_data: Dict[str, Dict[str, List[Dict]]],
    neg_ratio: float,
    seed: int,
) -> List[Dict[str, Any]]:
    """
    æ·»åŠ hard negativesï¼šä½¿ç”¨ç›¸åŒçš„Aï¼Œä½†Bæ¥è‡ªåŒä¸€sceneçš„ä¸åŒuid
    """
    if neg_ratio <= 0:
        return samples
    
    random.seed(seed)
    negatives = []
    
    # æŒ‰scene_idåˆ†ç»„samples
    samples_by_scene = {}
    for sample in samples:
        # ä»idæå–scene_id: {scene_id}_uid{uid}_...
        parts = sample['id'].split('_uid')
        if len(parts) < 2:
            continue
        scene_id = parts[0]
        if scene_id not in samples_by_scene:
            samples_by_scene[scene_id] = []
        samples_by_scene[scene_id].append(sample)
    
    for scene_id, scene_samples in samples_by_scene.items():
        if scene_id not in scene_data:
            continue
        
        # æ”¶é›†è¯¥sceneçš„æ‰€æœ‰uidçš„viewä¿¡æ¯
        other_uids = {}
        for uid, uid_views in scene_data[scene_id].items():
            if uid not in other_uids:
                other_uids[uid] = []
            for view in uid_views:
                other_uids[uid].append(view)
        
        for sample in scene_samples:
            # æå–å½“å‰sampleçš„uid
            parts = sample['id'].split('_uid')
            if len(parts) < 2:
                continue
            current_uid = parts[1].split('_')[0]
            
            # æ¯ä¸ªæ­£æ ·æœ¬æ·»åŠ floor(neg_ratio)ä¸ªè´Ÿæ ·æœ¬
            n_neg = int(neg_ratio)
            if random.random() < (neg_ratio - n_neg):
                n_neg += 1
            
            for _ in range(n_neg):
                # éšæœºé€‰æ‹©ä¸åŒçš„uid
                available_uids = [uid for uid in other_uids.keys() if uid != current_uid and other_uids[uid]]
                if not available_uids:
                    break
                
                other_uid = random.choice(available_uids)
                other_views = other_uids[other_uid]
                if not other_views:
                    continue
                
                # éšæœºé€‰æ‹©è¯¥uidçš„ä¸€ä¸ªviewä½œä¸ºB
                other_view = random.choice(other_views)
                other_orig = Path(other_view['original'])
                if not other_orig.exists():
                    continue
                
                # åˆ›å»ºè´Ÿæ ·æœ¬
                neg_id = sample['id'] + f"_NEG_{other_uid}"
                neg_sample = {
                    "id": neg_id,
                    "image": [
                        sample['image'][0],  # ç›¸åŒçš„A
                        str(other_orig.resolve())  # ä¸åŒçš„Bï¼ˆç»å¯¹è·¯å¾„ï¼‰
                    ],
                    "conversations": [
                        {"from": "human", "value": sample['conversations'][0]['value']},
                        {"from": "gpt", "value": "NOT_VISIBLE"}
                    ]
                }
                negatives.append(neg_sample)
    
    return samples + negatives


def main():
    parser = argparse.ArgumentParser(description="æ„å»ºå¤šè§†è§’ä¸€è‡´æ€§SFTè®­ç»ƒæ•°æ®")
    parser.add_argument("--data_root", type=str,
                       default="/local_data/jz4725/scannet_inpainted_dilate002_15obj_5frames_corrected",
                       help="æ•°æ®æ ¹ç›®å½•")
    parser.add_argument("--out_dir", type=str, required=True,
                       help="è¾“å‡ºç›®å½•")
    parser.add_argument("--mode", type=str, default="anchor", choices=["anchor", "allpairs"],
                       help="é…å¯¹æ¨¡å¼ï¼šanchoræˆ–allpairs")
    parser.add_argument("--anchor_k", type=int, default=1,
                       help="anchoræ¨¡å¼çš„å‚è€ƒviewç¼–å·ï¼ˆ1-5ï¼‰")
    parser.add_argument("--neg_ratio", type=float, default=0.0,
                       help="è´Ÿæ ·æœ¬æ¯”ä¾‹ï¼ˆhard negativesï¼‰")
    parser.add_argument("--alpha", type=float, default=0.45,
                       help="æ ‡è®°å›¾åƒçš„overlayé€æ˜åº¦")
    parser.add_argument("--seed", type=int, default=42,
                       help="éšæœºç§å­")
    
    args = parser.parse_args()
    
    random.seed(args.seed)
    np.random.seed(args.seed)
    
    data_root = Path(args.data_root)
    out_dir = Path(args.out_dir)
    out_dir.mkdir(parents=True, exist_ok=True)
    
    marked_dir = out_dir / "mv_marked_images_abs"
    marked_dir.mkdir(parents=True, exist_ok=True)
    
    print(f"ğŸ“‚ æ•°æ®æ ¹ç›®å½•: {data_root}")
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {out_dir}")
    print(f"ğŸ¯ æ¨¡å¼: {args.mode}")
    if args.mode == "anchor":
        print(f"   Anchor view: {args.anchor_k}")
    print(f"ğŸ“Š è´Ÿæ ·æœ¬æ¯”ä¾‹: {args.neg_ratio}")
    print()
    
    all_samples_train = []
    all_samples_val = []
    
    # å¤„ç†trainå’Œvalidation
    for split in ["train", "validation"]:
        split_dir = data_root / split
        if not split_dir.exists():
            print(f"âš ï¸  Splitç›®å½•ä¸å­˜åœ¨: {split_dir}")
            continue
        
        print(f"å¤„ç† {split} split...")
        
        # æ”¶é›†sceneæ•°æ®ï¼ˆç”¨äºhard negativesï¼‰
        scene_data = {}
        
        samples = []
        scene_count = 0
        
        for scene_dir in sorted(split_dir.iterdir()):
            if not scene_dir.is_dir():
                continue
            
            scene_id = scene_dir.name
            scene_data[scene_id] = {}
            
            for uid_dir in sorted(scene_dir.iterdir()):
                if not uid_dir.is_dir() or not uid_dir.name.startswith("uid_"):
                    continue
                
                uid = uid_dir.name.replace("uid_", "")
                
                # æ„å»ºè¯¥uidçš„æ ·æœ¬
                uid_samples = build_samples_for_uid(
                    scene_id, uid, uid_dir, marked_dir, split, args.mode, args.anchor_k, args.alpha, args.seed
                )
                
                # æ”¶é›†viewä¿¡æ¯ç”¨äºhard negatives
                views_list = []
                for k in range(1, 6):
                    orig_path, mask_path = find_frame_files(uid_dir, k)
                    if orig_path:
                        views_list.append({"original": str(orig_path)})
                scene_data[scene_id][uid] = views_list
                
                samples.extend(uid_samples)
            
            scene_count += 1
            if scene_count % 10 == 0:
                print(f"  å·²å¤„ç† {scene_count} ä¸ªåœºæ™¯...")
        
        # æ·»åŠ hard negatives
        if args.neg_ratio > 0:
            print(f"  æ·»åŠ hard negatives...")
            samples = add_hard_negatives(samples, scene_data, args.neg_ratio, args.seed)
        
        if split == "train":
            all_samples_train = samples
        else:
            all_samples_val = samples
        
        print(f"âœ… {split}: {len(samples)} ä¸ªæ ·æœ¬")
    
    # ä¿å­˜JSON
    train_json = out_dir / "mv_train.json"
    val_json = out_dir / "mv_val.json"
    
    with open(train_json, 'w') as f:
        json.dump(all_samples_train, f, indent=2, ensure_ascii=False)
    
    with open(val_json, 'w') as f:
        json.dump(all_samples_val, f, indent=2, ensure_ascii=False)
    
    print()
    print("="*70)
    print("âœ… æ•°æ®ç”Ÿæˆå®Œæˆï¼")
    print("="*70)
    print(f"è®­ç»ƒæ•°æ®: {train_json} ({len(all_samples_train)} ä¸ªæ ·æœ¬)")
    print(f"éªŒè¯æ•°æ®: {val_json} ({len(all_samples_val)} ä¸ªæ ·æœ¬)")
    print(f"æ ‡è®°å›¾åƒç›®å½•: {marked_dir}")


if __name__ == "__main__":
    main()
