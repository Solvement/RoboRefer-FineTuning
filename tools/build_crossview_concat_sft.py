#!/usr/bin/env python3
"""
ä» five_frames æ•°æ®ç”Ÿæˆæ‹¼æ¥å›¾æ ¼å¼çš„ CrossView SFT è®­ç»ƒæ•°æ®ï¼ˆåªåŒ…å«æ­£ä¾‹ï¼Œä¸åŒ…å«è´Ÿä¾‹ï¼‰

è¾“å…¥ï¼š
  - five_frames æ•°æ®ç›®å½•
è¾“å‡ºï¼š
  - æ‹¼æ¥å›¾å›¾åƒç›®å½•
  - SFTè®­ç»ƒJSONï¼ˆæ‹¼æ¥å›¾æ ¼å¼ï¼ŒåªåŒ…å«æ­£ä¾‹ï¼‰
"""

import argparse
import json
import random
from pathlib import Path
from typing import List, Dict, Any, Tuple, Optional

import cv2
import numpy as np
from PIL import Image


def load_mask(mask_path: Path) -> Optional[np.ndarray]:
    """è¯»å–maskä¸ºç°åº¦å›¾ï¼›è¯»å–å¤±è´¥è¿”å›Noneã€‚"""
    if not mask_path.exists():
        return None
    m = cv2.imread(str(mask_path), cv2.IMREAD_GRAYSCALE)
    return m


def sample_point_from_mask(mask: np.ndarray, use_center: bool = True) -> Optional[Tuple[float, float]]:
    """
    ä»maskä¸­é‡‡æ ·ä¸€ä¸ªç‚¹ï¼ˆå½’ä¸€åŒ–åæ ‡ï¼‰
    å¦‚æœuse_center=Trueï¼Œä½¿ç”¨distance transformæ‰¾ä¸­å¿ƒç‚¹ï¼›å¦åˆ™éšæœºé‡‡æ ·
    """
    if use_center:
        # ä½¿ç”¨distance transformæ‰¾ä¸­å¿ƒç‚¹
        dist = cv2.distanceTransform(mask, cv2.DIST_L2, 5)
        max_loc = np.unravel_index(np.argmax(dist), dist.shape)
        y, x = max_loc
        h, w = mask.shape
        return (x / (w - 1), y / (h - 1))
    else:
        # éšæœºé‡‡æ ·
        ys, xs = np.where(mask > 0)
        if len(xs) == 0:
            return None
        i = np.random.randint(0, len(xs))
        y, x = ys[i], xs[i]
        h, w = mask.shape
        return (x / (w - 1), y / (h - 1))


def make_concat_image(img_a_path: Path, img_b_path: Path, out_path: Path):
    """æ¨ªå‘æ‹¼æ¥ A/B ä¸¤å¼ å›¾ï¼Œå¹¶ä¿å­˜åˆ° out_pathã€‚"""
    img_a = Image.open(img_a_path).convert("RGB")
    img_b = Image.open(img_b_path).convert("RGB")

    # ç»Ÿä¸€é«˜åº¦ï¼ŒæŒ‰æ¯”ä¾‹ç¼©æ”¾å®½åº¦ï¼ˆä¿æŒçºµæ¨ªæ¯”ï¼‰
    h = max(img_a.height, img_b.height)

    def resize_to_h(img: Image.Image, target_h: int) -> Image.Image:
        if img.height == target_h:
            return img
        scale = target_h / img.height
        new_w = int(round(img.width * scale))
        return img.resize((new_w, target_h), Image.BILINEAR)

    img_a_r = resize_to_h(img_a, h)
    img_b_r = resize_to_h(img_b, h)

    w_total = img_a_r.width + img_b_r.width
    concat = Image.new("RGB", (w_total, h))
    concat.paste(img_a_r, (0, 0))
    concat.paste(img_b_r, (img_a_r.width, 0))

    out_path.parent.mkdir(parents=True, exist_ok=True)
    concat.save(out_path)


def build_human_prompt(label: str) -> str:
    """æ„å»ºhuman prompt"""
    return f"åœ¨Image Aä¸­ç”¨çº¢è‰²markeræ ‡è®°äº†ç›®æ ‡ç‰©ä½“ã€‚è¯·åœ¨Image Bä¸­æ‰¾åˆ°è¯¥ç‰©ä½“ï¼Œå¹¶è¾“å‡ºå…¶åœ¨Image Bä¸­çš„å½’ä¸€åŒ–åæ ‡ã€‚å¦‚æœè¯¥ç‰©ä½“åœ¨Image Bä¸­ä¸å¯è§ï¼Œè¯·è¾“å‡ºNOT_VISIBLEã€‚"


def load_five_frames_data(root_dir: Path, split: str = "both") -> Dict[str, Dict[str, List[Dict]]]:
    """
    åŠ è½½five_framesæ•°æ®
    è¿”å›: {scene_id: {uid: [frame1, frame2, ...]}}
    """
    data = {}
    
    splits = ["train", "validation"] if split == "both" else [split]
    
    for split_name in splits:
        split_dir = root_dir / split_name
        if not split_dir.exists():
            print(f"âš ï¸  Splitç›®å½•ä¸å­˜åœ¨: {split_dir}")
            continue
        
        for scene_dir in sorted(split_dir.iterdir()):
            if not scene_dir.is_dir():
                continue
            
            scene_id = scene_dir.name
            if scene_id not in data:
                data[scene_id] = {}
            
            for uid_dir in sorted(scene_dir.iterdir()):
                if not uid_dir.is_dir() or not uid_dir.name.startswith("uid_"):
                    continue
                
                uid = uid_dir.name.replace("uid_", "")
                json_file = uid_dir / f"{scene_id}_uid_{uid}_five_frames.json"
                
                if not json_file.exists():
                    continue
                
                with open(json_file, 'r') as f:
                    frames = json.load(f)
                
                if uid not in data[scene_id]:
                    data[scene_id][uid] = []
                
                # ç¡®ä¿è·¯å¾„æ˜¯ç»å¯¹è·¯å¾„
                for frame in frames:
                    if "original" in frame:
                        orig_path = Path(frame["original"])
                        if not orig_path.is_absolute():
                            frame["original"] = str(uid_dir / orig_path)
                        else:
                            frame["original"] = str(orig_path)
                    
                    if "mask" in frame:
                        mask_path = Path(frame["mask"])
                        if not mask_path.is_absolute():
                            frame["mask"] = str(uid_dir / mask_path)
                        else:
                            frame["mask"] = str(mask_path)
                
                data[scene_id][uid].extend(frames)
    
    return data


def build_concat_positives(
    data: Dict[str, Dict[str, List[Dict]]],
    root_dir: Path,
    concat_root: Path,
    max_pairs_per_uid: int = 8,
    min_mask_area: int = 100,
) -> List[Dict[str, Any]]:
    """
    æ„å»ºæ‹¼æ¥å›¾æ ¼å¼çš„æ­£ä¾‹ï¼ˆåªåŒ…å«æ­£ä¾‹ï¼Œä¸åŒ…å«è´Ÿä¾‹ï¼‰
    """
    positives = []
    
    for scene_id, uids in data.items():
        for uid, frames in uids.items():
            if len(frames) < 2:
                continue
            
            # A: ç¬¬ä¸€ä¸ªframeï¼ˆæ ‡è®°äº†ç›®æ ‡ç‰©ä½“ï¼‰
            ref = frames[0]
            ref_img = Path(ref["original"])
            label = ref.get("label", "")
            frame_a = str(ref.get("frame_id", ""))
            
            # B: å…¶ä½™framesï¼ˆæœ€å¤šmax_pairs_per_uidä¸ªï¼‰
            available_b_frames = frames[1:]
            if len(available_b_frames) > max_pairs_per_uid:
                available_b_frames = random.sample(available_b_frames, max_pairs_per_uid)
            
            for b in available_b_frames:
                b_img = Path(b["original"])
                b_mask = Path(b["mask"])
                frame_b = str(b.get("frame_id", ""))
                
                # æ£€æŸ¥Bçš„mask
                mask = load_mask(b_mask)
                if mask is None:
                    continue
                
                # è¿‡æ»¤æ‰maskå¤ªå°çš„æ­£ä¾‹
                mask_area = np.sum(mask > 0)
                if mask_area < min_mask_area:
                    continue
                
                # ä½¿ç”¨distance transformæ‰¾maskä¸­å¿ƒç‚¹ï¼ˆæ›´ç¡®å®šæ€§ï¼‰
                pt = sample_point_from_mask(mask, use_center=True)
                if pt is None:
                    continue
                
                x, y = pt
                # æ³¨æ„ï¼šæ‹¼æ¥å›¾ä¸­ï¼ŒBå›¾åœ¨å³ä¾§ï¼Œéœ€è¦å°†Bå›¾çš„å½’ä¸€åŒ–åæ ‡è½¬æ¢ä¸ºæ‹¼æ¥å›¾çš„å½’ä¸€åŒ–åæ ‡
                # å‡è®¾æ‹¼æ¥å›¾æ˜¯Aå’ŒBæ¨ªå‘æ‹¼æ¥ï¼ŒAåœ¨å·¦ï¼ŒBåœ¨å³
                # å¦‚æœAå’ŒBé«˜åº¦ç›¸åŒï¼Œé‚£ä¹ˆBå›¾çš„xåæ ‡éœ€è¦åŠ ä¸ŠAå›¾çš„å®½åº¦æ¯”ä¾‹
                # ä½†è¿™é‡Œæˆ‘ä»¬ç›´æ¥è¾“å‡ºBå›¾çš„å½’ä¸€åŒ–åæ ‡ï¼ˆåœ¨Bå›¾åæ ‡ç³»ä¸­ï¼‰
                # å› ä¸ºpromptä¸­è¯´çš„æ˜¯"åœ¨Image Bä¸­çš„å½’ä¸€åŒ–åæ ‡"
                ans = f"[({x:.3f}, {y:.3f})]"
                
                sample_id = f"{scene_id}_uid{uid}_A{frame_a}_B{frame_b}"
                
                # ç”Ÿæˆæ‹¼æ¥å›¾
                # æ„é€ ç›¸å¯¹è·¯å¾„ï¼ˆæ²¿ç”¨ scene/uid/filename ç»“æ„ï¼‰
                img_str = str(ref_img)
                if str(root_dir) in img_str:
                    rel = img_str.split(str(root_dir) + "/")[-1]
                else:
                    rel = ref_img.name
                
                rel_path = Path(rel)
                concat_rel = rel_path.with_name(rel_path.stem + f"_concat_A{frame_a}_B{frame_b}.png")
                concat_full = concat_root / concat_rel
                
                try:
                    make_concat_image(ref_img, b_img, concat_full)
                except Exception as e:
                    print(f"âš ï¸  æ‹¼æ¥å¤±è´¥ï¼Œè·³è¿‡æ ·æœ¬ {sample_id}: {e}")
                    continue
                
                human = build_human_prompt(label)
                
                # æ‹¼æ¥å›¾æ ¼å¼ï¼šimageå­—æ®µæ˜¯ä¸€ä¸ªåˆ—è¡¨ï¼Œä½†åªåŒ…å«ä¸€å¼ æ‹¼æ¥å›¾çš„è·¯å¾„
                sample_dict = {
                    "id": sample_id,
                    "image": [str(concat_full)],  # æ‹¼æ¥å›¾æ ¼å¼ï¼šåªåŒ…å«ä¸€å¼ æ‹¼æ¥å›¾
                    "conversations": [
                        {"from": "human", "value": human},
                        {"from": "gpt", "value": ans}
                    ]
                }
                
                positives.append(sample_dict)
    
    return positives


def main():
    ap = argparse.ArgumentParser(description="ç”Ÿæˆæ‹¼æ¥å›¾æ ¼å¼çš„CrossView SFTè®­ç»ƒæ•°æ®ï¼ˆåªåŒ…å«æ­£ä¾‹ï¼‰")
    ap.add_argument("--five_frames_root", required=True,
                   help="five_framesæ•°æ®æ ¹ç›®å½•ï¼Œä¾‹å¦‚ /local_data/jz4725/scannet_inpainted_dilate002_15obj_5frames_corrected")
    ap.add_argument("--out_json", required=True,
                   help="è¾“å‡ºSFTè®­ç»ƒJSONè·¯å¾„")
    ap.add_argument("--concat_root", required=True,
                   help="æ‹¼æ¥å›¾è¾“å‡ºæ ¹ç›®å½•")
    ap.add_argument("--split", type=str, default="both", choices=["train", "validation", "both"],
                   help="ä½¿ç”¨å“ªä¸ªsplitçš„æ•°æ®")
    ap.add_argument("--max_pairs_per_uid", type=int, default=8,
                   help="æ¯ä¸ªuidæœ€å¤šç”Ÿæˆå¤šå°‘å¯¹(A,B)ï¼Œé»˜è®¤8")
    ap.add_argument("--min_mask_area", type=int, default=100,
                   help="æœ€å°maské¢ç§¯ï¼ˆåƒç´ ï¼‰ï¼Œé»˜è®¤100")
    ap.add_argument("--seed", type=int, default=42,
                   help="éšæœºç§å­")
    
    args = ap.parse_args()
    
    random.seed(args.seed)
    np.random.seed(args.seed)
    
    root_dir = Path(args.five_frames_root)
    if not root_dir.exists():
        print(f"âŒ æ•°æ®æ ¹ç›®å½•ä¸å­˜åœ¨: {root_dir}")
        return
    
    concat_root = Path(args.concat_root)
    concat_root.mkdir(parents=True, exist_ok=True)
    
    print(f"ğŸ“‚ åŠ è½½five_framesæ•°æ®: {root_dir}")
    data = load_five_frames_data(root_dir, args.split)
    print(f"âœ… åŠ è½½äº† {len(data)} ä¸ªåœºæ™¯")
    
    print(f"ğŸ”¨ æ„å»ºæ‹¼æ¥å›¾æ­£ä¾‹ï¼ˆä¸åŒ…å«è´Ÿä¾‹ï¼‰...")
    positives = build_concat_positives(
        data,
        root_dir,
        concat_root,
        max_pairs_per_uid=args.max_pairs_per_uid,
        min_mask_area=args.min_mask_area
    )
    
    print(f"âœ… ç”Ÿæˆäº† {len(positives)} ä¸ªæ­£ä¾‹æ ·æœ¬")
    
    # ä¿å­˜JSON
    out_json = Path(args.out_json)
    out_json.parent.mkdir(parents=True, exist_ok=True)
    with open(out_json, 'w') as f:
        json.dump(positives, f, indent=2, ensure_ascii=False)
    
    print(f"âœ… æ•°æ®ä¿å­˜å®Œæˆï¼")
    print(f"   JSONæ–‡ä»¶: {out_json}")
    print(f"   æ‹¼æ¥å›¾ç›®å½•: {concat_root}")
    print(f"   æ ·æœ¬æ•°: {len(positives)} (åªåŒ…å«æ­£ä¾‹)")


if __name__ == "__main__":
    main()
