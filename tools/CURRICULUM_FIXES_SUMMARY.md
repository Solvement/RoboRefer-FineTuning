# Curriculum è®­ç»ƒè„šæœ¬ä¿®å¤æ€»ç»“

## âœ… å·²ä¿®å¤çš„é—®é¢˜

### 1. **max_steps è¯­ä¹‰ä¿®å¤ï¼ˆå…³é”®ä¿®å¤ï¼‰**
**é—®é¢˜**: Stage 2/3 ä½¿ç”¨ç›¸å¯¹æ­¥æ•°ï¼ˆ60/100ï¼‰ï¼Œä½† HF Trainer çš„ `max_steps` æ˜¯ç´¯è®¡æ­¥æ•°ä¸Šé™ã€‚

**ä¿®å¤**:
- Stage 1: `max_steps=40` (0 -> 40)
- Stage 2: `max_steps=100` (40 -> 100, é¢å¤– 60 æ­¥) âœ… ä» 60 æ”¹ä¸º 100
- Stage 3: `max_steps=200` (100 -> 200, é¢å¤– 100 æ­¥) âœ… ä» 100 æ”¹ä¸º 200

### 2. **Resume é€»è¾‘ä¿®å¤**
**é—®é¢˜**: Stage 2/3 åªä½¿ç”¨ `model_name_or_path`ï¼Œæ²¡æœ‰æ˜¾å¼æŒ‡å®š `resume_from_checkpoint`ï¼Œå¯¼è‡´ optimizer/scheduler/global_step æœªæ¢å¤ã€‚

**ä¿®å¤**:
- Stage 2/3 ç°åœ¨åŒæ—¶ä½¿ç”¨ï¼š
  - `--model_name_or_path`: æŒ‡å‘ä¸Šä¸€é˜¶æ®µçš„ output_dirï¼ˆåŠ è½½æ¨¡å‹æƒé‡ï¼‰
  - `--resume_from_checkpoint`: æŒ‡å‘ä¸Šä¸€é˜¶æ®µçš„ checkpoint ç›®å½•ï¼ˆæ¢å¤è®­ç»ƒçŠ¶æ€ï¼‰

### 3. **æ—¥å¿—æ•è·ä¿®å¤**
**é—®é¢˜**: åªæ•è·äº† stdoutï¼Œstderr ä¸­çš„é”™è¯¯ä¿¡æ¯ä¸¢å¤±ã€‚

**ä¿®å¤**:
- ä½¿ç”¨ `subprocess.run(..., stderr=subprocess.STDOUT)` åˆå¹¶ stderr åˆ° stdout
- ä¿å­˜å®Œæ•´æ—¥å¿—åˆ° `{output_dir}/stage_{name}_full.log`
- æ·»åŠ ç¯å¢ƒå˜é‡ `PYTHONFAULTHANDLER=1` å’Œ `TORCH_SHOW_CPP_STACKTRACES=1` ä»¥è·å–æ›´è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯

### 4. **è¯­æ³•é”™è¯¯ä¿®å¤**
**é—®é¢˜**: `cmd.extend([...])` ç¼ºå°‘é—­åˆæ‹¬å· `)`ã€‚

**ä¿®å¤**: åœ¨ç¬¬265è¡Œçš„ `]` åæ·»åŠ äº† `)`ã€‚

### 5. **å†…å­˜ä¼˜åŒ–ï¼ˆå·²åº”ç”¨ï¼‰**
- Stage 1: `max_tiles=6`, `dataloader_workers=4`
- Stage 2/3: `max_tiles=4`, `dataloader_workers=2`
- `torch_empty_cache_steps=1` (æ›´é¢‘ç¹çš„ç¼“å­˜æ¸…ç†)

---

## ğŸ“‹ ä¿®å¤åçš„é…ç½®

### Stage 1
- **Max Steps**: 40 (ç´¯è®¡)
- **Resume**: ä» `BASE_MODEL` å¼€å§‹
- **Output**: `Curriculum-25pct-Stage1/`

### Stage 2
- **Max Steps**: 100 (ç´¯è®¡ï¼Œä» 40 ç»§ç»­)
- **Resume**: 
  - `model_name_or_path`: `Curriculum-25pct-Stage1/`
  - `resume_from_checkpoint`: `Curriculum-25pct-Stage1/checkpoint-40`
- **Output**: `Curriculum-25pct-Stage2/`

### Stage 3
- **Max Steps**: 200 (ç´¯è®¡ï¼Œä» 100 ç»§ç»­)
- **Resume**: 
  - `model_name_or_path`: `Curriculum-25pct-Stage2/`
  - `resume_from_checkpoint`: `Curriculum-25pct-Stage2/checkpoint-100`
- **Output**: `Curriculum-25pct-Stage3/`

---

## ğŸš€ è¿è¡Œè®­ç»ƒ

ç°åœ¨å¯ä»¥è¿è¡Œä¿®å¤åçš„è®­ç»ƒè„šæœ¬ï¼š

```bash
cd /local_data/ky2738/snpp-msg/snpp-msg-conversion/scannetpp-main/RoboRefer
python3 tools/run_curriculum_3stage.py
```

æˆ–è€…æ‰‹åŠ¨è¿è¡Œ Stage 2ï¼ˆç”¨äºè°ƒè¯•ï¼‰ï¼š

```bash
cd /local_data/ky2738/snpp-msg/snpp-msg-conversion/scannetpp-main/RoboRefer

export PYTHONFAULTHANDLER=1
export TORCH_SHOW_CPP_STACKTRACES=1

/local_data/ky2738/envs/snpp2msg-rast/bin/python -m torch.distributed.run \
  --nnodes=1 --nproc_per_node=1 --master_port 29521 \
  llava/train/train_mem.py \
  --deepspeed scripts/zero3.json \
  --model_name_or_path runs/train/Curriculum-25pct-Stage1 \
  --resume_from_checkpoint runs/train/Curriculum-25pct-Stage1/checkpoint-40 \
  --data_mixture crossview_multimg_25pct_pos_tierA \
  --output_dir runs/train/Curriculum-25pct-Stage2 \
  --max_steps 100 \
  --max_tiles 4 \
  --dataloader_num_workers 2 \
  --torch_empty_cache_steps 1 \
  --bf16 True \
  2>&1 | tee runs/train/Curriculum-25pct-Stage2/manual_stage2_full.log
```

---

## âœ… éªŒè¯æ£€æŸ¥ç‚¹

è®­ç»ƒå®Œæˆåï¼Œæ£€æŸ¥ï¼š

1. **Stage 1**: `trainer_state.json` ä¸­ `global_step=40`
2. **Stage 2**: `trainer_state.json` ä¸­ `global_step=100`
3. **Stage 3**: `trainer_state.json` ä¸­ `global_step=200`

å¦‚æœæ­¥æ•°ä¸åŒ¹é…ï¼Œæ£€æŸ¥å¯¹åº”çš„ `stage_{name}_full.log` æ–‡ä»¶ä»¥æŸ¥çœ‹è¯¦ç»†é”™è¯¯ä¿¡æ¯ã€‚
