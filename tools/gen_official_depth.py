#!/usr/bin/env python3
"""
ä½¿ç”¨RoboReferå®˜æ–¹çš„Depth Anything V2ç”Ÿæˆdepthå›¾åƒ

è¾“å…¥ï¼šRGBå›¾åƒæ ¹ç›®å½•æˆ–å›¾åƒè·¯å¾„åˆ—è¡¨
è¾“å‡ºï¼šdepthå›¾åƒåˆ°é•œåƒç›®å½•ç»“æ„ï¼Œç”Ÿæˆdepth_map.jsonæ˜ å°„æ–‡ä»¶
"""
import argparse
import json
import sys
from pathlib import Path
import torch
import cv2
import numpy as np
from PIL import Image
from tqdm import tqdm

# å¯¼å…¥RoboReferå®˜æ–¹çš„Depth Anything V2
sys.path.insert(0, str(Path(__file__).parent.parent / "API" / "Depth_Anything_V2"))
from depth_anything_v2.dpt import DepthAnythingV2


def load_depth_anything_model(encoder='vitl', device='cuda', checkpoint_path=None):
    """åŠ è½½RoboReferå®˜æ–¹çš„Depth Anything V2æ¨¡å‹"""
    model_configs = {
        'vits': {'encoder': 'vits', 'features': 64, 'out_channels': [48, 96, 192, 384]},
        'vitb': {'encoder': 'vitb', 'features': 128, 'out_channels': [96, 192, 384, 768]},
        'vitl': {'encoder': 'vitl', 'features': 256, 'out_channels': [256, 512, 1024, 1024]},
        'vitg': {'encoder': 'vitg', 'features': 384, 'out_channels': [1536, 1536, 1536, 1536]}
    }
    
    if encoder not in model_configs:
        raise ValueError(f"Unknown encoder: {encoder}. Choose from {list(model_configs.keys())}")
    
    model = DepthAnythingV2(**model_configs[encoder])
    
    # å°è¯•åŠ è½½checkpoint
    if checkpoint_path is None:
        # é»˜è®¤checkpointè·¯å¾„
        checkpoint_path = f'/home/zhouenshen/ckpt/depthanything/depth_anything_v2_{encoder}.pth'
        # å¦‚æœé»˜è®¤è·¯å¾„ä¸å­˜åœ¨ï¼Œå°è¯•å…¶ä»–å¸¸è§è·¯å¾„
        if not Path(checkpoint_path).exists():
            alt_paths = [
                f'/local_data/cy2932/checkpoints/depth/depth_anything_v2_{encoder}.pth',
                f'checkpoints/depth_anything_v2_{encoder}.pth',
                f'./checkpoints/depth_anything_v2_{encoder}.pth',
                f'API/Depth_Anything_V2/checkpoints/depth_anything_v2_{encoder}.pth',
            ]
            for alt_path in alt_paths:
                if Path(alt_path).exists():
                    checkpoint_path = alt_path
                    break
    
    if not Path(checkpoint_path).exists():
        # å°è¯•ä½¿ç”¨transformersåº“çš„HuggingFaceæ¨¡å‹
        print(f"âš ï¸  Checkpoint not found: {checkpoint_path}")
        print(f"   å°è¯•ä½¿ç”¨HuggingFace transformersæ¨¡å‹...")
        try:
            from transformers import AutoImageProcessor, AutoModelForDepthEstimation
            model_name_map = {
                'vits': 'LiheYoung/depth-anything-v2-small-hf',
                'vitb': 'LiheYoung/depth-anything-v2-base-hf',
                'vitl': 'LiheYoung/depth-anything-v2-large-hf',
                'vitg': 'LiheYoung/depth-anything-v2-large-hf'  # vitg fallback to large
            }
            model_name = model_name_map.get(encoder, model_name_map['vitl'])
            print(f"   ä½¿ç”¨HuggingFaceæ¨¡å‹: {model_name}")
            processor = AutoImageProcessor.from_pretrained(model_name)
            model = AutoModelForDepthEstimation.from_pretrained(model_name)
            model = model.to(device).eval()
            return (processor, model, 'transformers')  # è¿”å›tupleæ ‡è¯†ä½¿ç”¨transformers
        except Exception as e:
            raise FileNotFoundError(
                f"Checkpoint not found: {checkpoint_path}\n"
                f"Transformers fallback also failed: {e}\n"
                f"Please download Depth Anything V2 {encoder} checkpoint and specify with --checkpoint"
            )
    
    model.load_state_dict(torch.load(checkpoint_path, map_location='cpu'))
    model = model.to(device).eval()
    return (model, 'official')  # è¿”å›tupleæ ‡è¯†ä½¿ç”¨å®˜æ–¹å®ç°


def generate_depth_image(model_info, rgb_path: Path, output_path: Path, device='cuda', input_size=518):
    """
    ä½¿ç”¨Depth Anything V2ç”Ÿæˆdepthå›¾åƒï¼ˆæ”¯æŒå®˜æ–¹å®ç°æˆ–transformersï¼‰
    
    è¾“å‡ºæ ¼å¼ï¼šuint16 PNGï¼Œå•ä½mmï¼ˆä¸RoboReferè®­ç»ƒæ ¼å¼ä¸€è‡´ï¼‰
    """
    try:
        # è¯»å–RGBå›¾åƒ
        raw_image = cv2.imread(str(rgb_path))
        if raw_image is None:
            print(f"âš ï¸  æ— æ³•è¯»å–å›¾åƒ: {rgb_path}")
            return False
        
        # åˆ¤æ–­ä½¿ç”¨å“ªç§å®ç°
        if isinstance(model_info, tuple) and len(model_info) == 2:
            model, model_type = model_info
        else:
            # å…¼å®¹æ—§ä»£ç 
            model = model_info
            model_type = 'official'
        
        if model_type == 'transformers':
            # ä½¿ç”¨transformersåº“
            processor, model_obj = model
            from PIL import Image as PILImage
            image_pil = PILImage.fromarray(cv2.cvtColor(raw_image, cv2.COLOR_BGR2RGB))
            inputs = processor(images=image_pil, return_tensors="pt").to(device)
            with torch.no_grad():
                outputs = model_obj(**inputs)
                predicted_depth = outputs.predicted_depth
            
            # è½¬æ¢ä¸ºnumpyå¹¶è°ƒæ•´å°ºå¯¸
            depth = predicted_depth.cpu().numpy()[0, 0]
            h, w = raw_image.shape[:2]
            from scipy.ndimage import zoom
            depth = zoom(depth, (h / depth.shape[0], w / depth.shape[1]))
        else:
            # ä½¿ç”¨å®˜æ–¹å®ç°
            depth = model.infer_image(raw_image, input_size, device=device)
        
        # è½¬æ¢ä¸ºuint16ï¼Œå•ä½mm
        # Depth Anythingè¾“å‡ºçš„æ˜¯ç›¸å¯¹æ·±åº¦ï¼Œéœ€è¦è½¬æ¢ä¸ºç»å¯¹æ·±åº¦ï¼ˆmmï¼‰
        # å‡è®¾æœ€å¤§æ·±åº¦ä¸º20mï¼ˆ20000mmï¼‰ï¼Œè¿™æ˜¯RoboReferå¸¸ç”¨çš„èŒƒå›´
        max_depth_mm = 20000
        depth_mm = (depth * max_depth_mm).clip(0, 65535).astype(np.uint16)
        
        # ä¿å­˜ä¸ºuint16 PNG
        output_path.parent.mkdir(parents=True, exist_ok=True)
        depth_img = Image.fromarray(depth_mm, mode='I;16')
        depth_img.save(output_path)
        
        return True
    except Exception as e:
        print(f"âš ï¸  ç”Ÿæˆdepthå¤±è´¥ {rgb_path}: {e}")
        import traceback
        traceback.print_exc()
        return False


def collect_image_files(input_path: Path, extensions=None):
    """æ”¶é›†æ‰€æœ‰å›¾åƒæ–‡ä»¶"""
    if extensions is None:
        extensions = {'.png', '.jpg', '.jpeg', '.PNG', '.JPG', '.JPEG'}
    
    image_files = []
    if input_path.is_file():
        if input_path.suffix.lower() in extensions:
            image_files.append(input_path)
    elif input_path.is_dir():
        for ext in extensions:
            image_files.extend(input_path.rglob(f'*{ext}'))
    
    return sorted(image_files)


def generate_depths(
    input_root: Path,
    output_root: Path,
    encoder='vitl',
    device='cuda',
    checkpoint_path=None,
    input_size=518,
    max_images=None
):
    """
    ä¸ºè¾“å…¥ç›®å½•ä¸­çš„æ‰€æœ‰RGBå›¾åƒç”Ÿæˆdepthå›¾åƒ
    
    Args:
        input_root: RGBå›¾åƒæ ¹ç›®å½•
        output_root: depthè¾“å‡ºæ ¹ç›®å½•ï¼ˆé•œåƒç»“æ„ï¼‰
    """
    print(f"ğŸ“‚ æ‰«æRGBå›¾åƒ: {input_root}")
    image_files = collect_image_files(input_root)
    print(f"âœ… æ‰¾åˆ° {len(image_files)} å¼ å›¾åƒ")
    
    # å¦‚æœæŒ‡å®šäº†max_imagesï¼Œåªå¤„ç†å‰Nå¼ ï¼ˆç”¨äºæµ‹è¯•ï¼‰
    if max_images is not None and max_images > 0:
        original_count = len(image_files)
        image_files = image_files[:max_images]
        print(f"ğŸ“ æµ‹è¯•æ¨¡å¼: åªå¤„ç†å‰ {len(image_files)}/{original_count} å¼ å›¾åƒ")
    
    if len(image_files) == 0:
        print("âŒ æœªæ‰¾åˆ°ä»»ä½•å›¾åƒæ–‡ä»¶")
        return False
    
    # åŠ è½½æ¨¡å‹
    print(f"ğŸ”§ åŠ è½½Depth Anything V2æ¨¡å‹ (encoder={encoder})...")
    try:
        model = load_depth_anything_model(encoder, device, checkpoint_path)
        print("âœ… æ¨¡å‹åŠ è½½å®Œæˆ")
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return False
    
    # ç”Ÿæˆdepthå¹¶æ„å»ºæ˜ å°„
    depth_map = {}
    success_count = 0
    
    for rgb_path in tqdm(image_files, desc="ç”Ÿæˆdepth"):
        # è®¡ç®—ç›¸å¯¹è·¯å¾„
        try:
            rel_path = rgb_path.relative_to(input_root)
        except ValueError:
            # å¦‚æœä¸åœ¨input_rootä¸‹ï¼Œä½¿ç”¨ç»å¯¹è·¯å¾„çš„basename
            rel_path = Path(rgb_path.name)
        
        # æ„é€ depthè¾“å‡ºè·¯å¾„ï¼ˆé•œåƒç»“æ„ï¼‰
        depth_path = output_root / rel_path
        # ä¿æŒç›¸åŒæ–‡ä»¶åï¼Œä½†ç¡®ä¿æ˜¯.pngæ ¼å¼
        depth_path = depth_path.parent / (depth_path.stem + '_depth.png')
        
        # å¦‚æœå·²å­˜åœ¨ï¼Œè·³è¿‡
        if depth_path.exists():
            depth_map[str(rel_path)] = str(depth_path.relative_to(output_root))
            success_count += 1
            continue
        
        # ç”Ÿæˆdepth
        if generate_depth_image(model, rgb_path, depth_path, device, input_size):
            depth_map[str(rel_path)] = str(depth_path.relative_to(output_root))
            success_count += 1
    
    # ä¿å­˜æ˜ å°„æ–‡ä»¶
    map_file = output_root / 'depth_map.json'
    with open(map_file, 'w') as f:
        json.dump(depth_map, f, indent=2)
    
    print(f"\nâœ… å®Œæˆï¼")
    print(f"   - æˆåŠŸç”Ÿæˆ: {success_count}/{len(image_files)} å¼ depthå›¾åƒ")
    print(f"   - è¾“å‡ºç›®å½•: {output_root}")
    print(f"   - æ˜ å°„æ–‡ä»¶: {map_file}")
    
    return True


def main():
    parser = argparse.ArgumentParser(
        description='ä½¿ç”¨RoboReferå®˜æ–¹çš„Depth Anything V2ç”Ÿæˆdepthå›¾åƒ'
    )
    parser.add_argument('--input-root', type=str, required=True,
                       help='RGBå›¾åƒæ ¹ç›®å½•')
    parser.add_argument('--output-root', type=str, required=True,
                       help='depthè¾“å‡ºæ ¹ç›®å½•ï¼ˆé•œåƒç»“æ„ï¼‰')
    parser.add_argument('--encoder', type=str, default='vitl',
                       choices=['vits', 'vitb', 'vitl', 'vitg'],
                       help='Depth Anything V2 encoder')
    parser.add_argument('--checkpoint', type=str, default=None,
                       help='æ¨¡å‹checkpointè·¯å¾„ï¼ˆå¦‚æœä¸åœ¨é»˜è®¤ä½ç½®ï¼‰')
    parser.add_argument('--device', type=str, default='cuda',
                       help='è®¾å¤‡ (cuda/cpu)')
    parser.add_argument('--input-size', type=int, default=518,
                       help='è¾“å…¥å›¾åƒå°ºå¯¸')
    parser.add_argument('--max-images', type=int, default=None,
                       help='æœ€å¤§å¤„ç†å›¾åƒæ•°é‡ï¼ˆç”¨äºæµ‹è¯•ï¼ŒNoneè¡¨ç¤ºå¤„ç†å…¨éƒ¨ï¼‰')
    
    args = parser.parse_args()
    
    generate_depths(
        Path(args.input_root),
        Path(args.output_root),
        args.encoder,
        args.device,
        args.checkpoint,
        args.input_size,
        args.max_images
    )


if __name__ == '__main__':
    main()
